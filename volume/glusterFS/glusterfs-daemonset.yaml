apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: job-access-role
  namespace: default  # Make sure this matches your namespace
rules:
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["batch"]
    resources: ["jobs"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["pods/exec"]
    verbs: ["create"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: job-access-rolebinding
  namespace: default
subjects:
  - kind: ServiceAccount
    name: default  # This binds the role to the default service account
    namespace: default
roleRef:
  kind: Role
  name: job-access-role  # The name of the role to bind
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: v1
kind: Secret
metadata:
  name: docker-credentials
type: Opaque
data:
  docker-username: ZG9ja2VyZWx2aXM=
  docker-password: U2ltb24xOTc4OTAjwqkj4oKsI+KCrCM=

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: dockerfile-config
data:
  Dockerfile: |
    # Dockerfile contents go here
    # Use an Ubuntu base image
    FROM ubuntu:20.04

    # Set non-interactive mode for apt-get to avoid any prompts
    ENV DEBIAN_FRONTEND=noninteractive

    # Install prerequisites including ping (iputils-ping)
    RUN apt-get update && \
        apt-get install -y software-properties-common curl iputils-ping && \
        apt-get clean

    # Add the GlusterFS PPA repository
    RUN add-apt-repository ppa:gluster/glusterfs-10

    # Update apt repositories
    RUN apt-get update

    # Install GlusterFS server
    RUN apt-get install -y glusterfs-server

    # Expose ports for GlusterFS if required
    EXPOSE 24007 24008 24009 24010

    # Set up GlusterFS as the default command (no need to use systemctl in Docker)
    CMD ["glusterd", "-N"]


---

apiVersion: batch/v1
kind: Job
metadata:
  name: docker-build-job
spec:
  template:
    spec:
      containers:
      - name: docker-build-container
        image: docker:19.03.12
        command:
        - /bin/sh
        - -c
        - |
          echo "Logging into Docker..."
          echo $DOCKER_PASSWORD | docker login -u $DOCKER_USERNAME --password-stdin

          echo "Checking Docker installation..."
          docker info

          echo "Building the image..."
          mkdir -p /docker-build
          cp /config/Dockerfile /docker-build/Dockerfile
          cd /docker-build
          docker build -t $DOCKER_USERNAME/glusterfs-image:latest .

          echo "Pushing the image to Docker Hub..."
          docker push $DOCKER_USERNAME/glusterfs-image:latest

          echo "Done"
        env:
        - name: DOCKER_USERNAME
          valueFrom:
            secretKeyRef:
              name: docker-credentials
              key: docker-username
        - name: DOCKER_PASSWORD
          valueFrom:
            secretKeyRef:
              name: docker-credentials
              key: docker-password
        volumeMounts:
        - name: dockerfile-volume
          mountPath: /config
        - name: docker-socket
          mountPath: /var/run/docker.sock
      volumes:
      - name: dockerfile-volume
        configMap:
          name: dockerfile-config
      - name: docker-socket
        hostPath:
          path: /var/run/docker.sock
          type: Socket
      restartPolicy: Never
  backoffLimit: 4

---

apiVersion: v1
kind: Service
metadata:
  name: glusterfs-service
spec:
  selector:
    app: glusterfs
  ports:
    - protocol: TCP
      port: 24007
      targetPort: 24007
  type: NodePort

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: glusterfs
spec:
  serviceName: "glusterfs-service"
  replicas: 3
  selector:
    matchLabels:
      app: glusterfs
  template:
    metadata:
      labels:
        app: glusterfs
    spec:
      initContainers:
      - name: wait-for-job
        image: bitnami/kubectl:latest
        command:
          - "/bin/sh"
          - "-c"
          - |
            # Wait until the job is successful
            until kubectl get jobs/docker-build-job -o=jsonpath='{.status.succeeded}' | grep -q '1'; do
              echo "Waiting for job to succeed..."
              sleep 5
            done
            echo "Job is successful, proceeding with the pod task."
      - name: set-permissions
        image: busybox:latest
        command:
          - "/bin/sh"
          - "-c"
          - |
            # Set executable permissions for all users on the directory
            chmod +x /mnt/glusterfs/$(hostname)
            echo "Permissions updated for /mnt/glusterfs/$(hostname)"
        volumeMounts:
        - name: glusterfs-data
          mountPath: /mnt/glusterfs
        - name: pod-name-dir
          mountPath: /mnt/glusterfs/$(hostname)
      containers:
      - name: glusterfs
        image: dockerelvis/glusterfs-image:latest
        ports:
        - containerPort: 24007
        - containerPort: 24008
        volumeMounts:
        - name: glusterfs-data
          mountPath: /mnt/glusterfs
        - name: pod-name-dir
          mountPath: /mnt/glusterfs/$(hostname)
      volumes:
      - name: glusterfs-data
        hostPath:
          path: /mnt/glusterfs
          type: DirectoryOrCreate
      - name: pod-name-dir
        emptyDir: {}
      - name: docker-socket
        hostPath:
          path: /var/run/docker.sock
          type: Socket

--- 
apiVersion: batch/v1
kind: Job
metadata:
  name: update-hosts-file-job
spec:
  template:
    spec:
      containers:
      - name: update-hosts-file
        image: bitnami/kubectl:latest
        securityContext:
          privileged: true
        command:
          - "/bin/sh"
          - "-c"
          - |
            # Wait until all 3 pods in the StatefulSet are running
            until [ $(kubectl get pods -l app=glusterfs -o=jsonpath='{.items[?(@.status.phase=="Running")].metadata.name}' | wc -w) -eq 3 ]; do
              echo "Waiting for all pods to be in Running state..."
              sleep 5
            done
            echo "All pods are running, proceeding with updating /etc/hosts."

            # Get the list of all pod names in the StatefulSet
            PODS=$(kubectl get pods -l app=glusterfs -o=jsonpath='{.items[*].metadata.name}')
            for POD in $PODS; do
              POD_IP=$(kubectl get pod $POD -o=jsonpath='{.status.podIP}')
              echo "$POD_IP $POD.glusterfs-service.default.svc.cluster.local $POD" >> /etc/hosts  # Add the pod IP and name to /etc/hosts
            done
      restartPolicy: Never
      securityContext:
        runAsUser: 0  # Run as root user (UID 0)
  backoffLimit: 4
